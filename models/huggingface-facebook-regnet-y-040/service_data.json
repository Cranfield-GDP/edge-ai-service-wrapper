{
    "model_name": "facebook/regnet-y-040",
    "model_url": "https://huggingface.co/facebook/regnet-y-040",
    "task": "image-classification",
    "task_detail": "The pre-trained AI model, facebook/regnet-y-040, is an advanced neural network designed specifically for image classification tasks. It leverages the RegNet architecture, which was developed with a focus on optimizing neural network design spaces through Neural Architecture Search (NAS). This model has been trained on the extensive ImageNet-1k dataset, which consists of 1,000 high-diversity image classes, making it highly proficient in classifying a wide variety of images.\n\n### Functionality and Features\n\n1. **Image Classification**: \n   - The model is capable of categorizing images into one of 1,000 distinct classes, as defined by the ImageNet-1k dataset. These classes cover an extensive range of objects, animals, scenes, and more, providing broad applicability across domains needing image recognition capabilities.\n\n2. **Input and Output Specifications**:\n   - **Input Format**: The expected input for this model is a tensor representation of an image. Users typically preprocess their images using specific feature extraction utilities, such as the AutoFeatureExtractor from the Hugging Face Transformers library, to convert raw image data into the appropriate tensor format the model can process.\n   - **Output Format**: The output is a tensor of logits, representing the model\u2019s confidence scores for each class. The class with the highest score is selected as the model's prediction. These raw predictions can be converted into human-readable class labels using the model's configuration mappings, providing interpretability of the results.\n\n3. **Use Cases**:\n   - The model's flexibility makes it suitable for various image classification needs in fields like wildlife monitoring (classifying species such as different types of cats), retail (identifying products like teapots), real estate (recognizing architectural styles or types of buildings), and more.\n   - It is designed for straightforward integration with fine-tuned versions for specialized classification tasks beyond the initial 1,000 ImageNet categories.\n\n4. **Operational Context**:\n   - The model is ideal for developers and researchers who need a robust image classification tool without the need to train a model from scratch. It supports seamless integration into Python-based environments using libraries such as PyTorch and datasets managed through the Hugging Face Hub.\n   - Users should be aware of existing limitations concerning novel or highly specific image classes not included in the ImageNet dataset, as the model might not perform optimally without further fine-tuning.\n\nIn summary, the facebook/regnet-y-040 model offers a powerful and versatile solution for image classification tasks, efficiently processing visual input data to deliver reliable and accurate categorization results suitable for a multitude of applications.",
    "accuracy_info": "No accuracy information found.",
    "image_repository_url": "docker.io/cranfield6g/cranfield-edge-facebook-regnet-y-040",
    "service_disk_size_bytes": 3742468200,
    "profiles": [
        {
            "node_id": "LAP004262",
            "device_type": "DeviceType.CPU",
            "device_name": "None",
            "initialization_time_ms": 7628.631114959717,
            "eviction_time_ms": 0,
            "initialization_cost": 0,
            "keep_alive_cost": 0,
            "energy_consumption_idle": 0,
            "inference": {
                "cpu_time_ms": 79.069468,
                "device_time_ms": 0.0,
                "cpu_memory_usage_MB": 0.003814697265625,
                "self_cpu_memory_usage_MB": -149.41693115234375,
                "device_memory_usage_MB": 0.0,
                "self_device_memory_usage_MB": 0.0,
                "energy_consumption_execution": 0,
                "disk_IO_MB": 0,
                "input_data_MB": 0,
                "output_data_MB": 0,
                "execution_time_ms": 304.78612581888837,
                "execution_cost": 0
            },
            "xai": [
                {
                    "xai_method": "GradCAM",
                    "cpu_time_ms": 311.311077,
                    "device_time_ms": 0.0,
                    "cpu_memory_usage_MB": 182.0909423828125,
                    "self_cpu_memory_usage_MB": -125.6288833618164,
                    "device_memory_usage_MB": 0.0,
                    "self_device_memory_usage_MB": 0.0,
                    "energy_consumption_execution": 0,
                    "disk_IO_MB": 0,
                    "input_data_MB": 0,
                    "output_data_MB": 0,
                    "execution_time_ms": 920.0631777445475,
                    "execution_cost": 0
                },
                {
                    "xai_method": "HiResCAM",
                    "cpu_time_ms": 272.17807500000004,
                    "device_time_ms": 0.0,
                    "cpu_memory_usage_MB": 103.3302001953125,
                    "self_cpu_memory_usage_MB": -125.6288833618164,
                    "device_memory_usage_MB": 0.0,
                    "self_device_memory_usage_MB": 0.0,
                    "energy_consumption_execution": 0,
                    "disk_IO_MB": 0,
                    "input_data_MB": 0,
                    "output_data_MB": 0,
                    "execution_time_ms": 909.6947511037191,
                    "execution_cost": 0
                },
                {
                    "xai_method": "XGradCAM",
                    "cpu_time_ms": 226.566732,
                    "device_time_ms": 0.0,
                    "cpu_memory_usage_MB": 103.3302001953125,
                    "self_cpu_memory_usage_MB": -125.6288833618164,
                    "device_memory_usage_MB": 0.0,
                    "self_device_memory_usage_MB": 0.0,
                    "energy_consumption_execution": 0,
                    "disk_IO_MB": 0,
                    "input_data_MB": 0,
                    "output_data_MB": 0,
                    "execution_time_ms": 779.9745400746664,
                    "execution_cost": 0
                },
                {
                    "xai_method": "GradCAMPlusPlus",
                    "cpu_time_ms": 241.774058,
                    "device_time_ms": 0.0,
                    "cpu_memory_usage_MB": 103.3302001953125,
                    "self_cpu_memory_usage_MB": -125.6288833618164,
                    "device_memory_usage_MB": 0.0,
                    "self_device_memory_usage_MB": 0.0,
                    "energy_consumption_execution": 0,
                    "disk_IO_MB": 0,
                    "input_data_MB": 0,
                    "output_data_MB": 0,
                    "execution_time_ms": 897.4621295928955,
                    "execution_cost": 0
                },
                {
                    "xai_method": "LayerCAM",
                    "cpu_time_ms": 632.074878,
                    "device_time_ms": 0.0,
                    "cpu_memory_usage_MB": 103.3302001953125,
                    "self_cpu_memory_usage_MB": -125.6288833618164,
                    "device_memory_usage_MB": 0.0,
                    "self_device_memory_usage_MB": 0.0,
                    "energy_consumption_execution": 0,
                    "disk_IO_MB": 0,
                    "input_data_MB": 0,
                    "output_data_MB": 0,
                    "execution_time_ms": 838.7383619944254,
                    "execution_cost": 0
                },
                {
                    "xai_method": "EigenCAM",
                    "cpu_time_ms": 167.71758399999996,
                    "device_time_ms": 0.0,
                    "cpu_memory_usage_MB": 103.1268310546875,
                    "self_cpu_memory_usage_MB": -46.868133544921875,
                    "device_memory_usage_MB": 0.0,
                    "self_device_memory_usage_MB": 0.0,
                    "energy_consumption_execution": 0,
                    "disk_IO_MB": 0,
                    "input_data_MB": 0,
                    "output_data_MB": 0,
                    "execution_time_ms": 454.1221459706624,
                    "execution_cost": 0
                },
                {
                    "xai_method": "EigenGradCAM",
                    "cpu_time_ms": 387.050316,
                    "device_time_ms": 0.0,
                    "cpu_memory_usage_MB": 103.3302001953125,
                    "self_cpu_memory_usage_MB": -125.6288833618164,
                    "device_memory_usage_MB": 0.0,
                    "self_device_memory_usage_MB": 0.0,
                    "energy_consumption_execution": 0,
                    "disk_IO_MB": 0,
                    "input_data_MB": 0,
                    "output_data_MB": 0,
                    "execution_time_ms": 890.840212504069,
                    "execution_cost": 0
                },
                {
                    "xai_method": "KPCA_CAM",
                    "cpu_time_ms": 90.11106400000001,
                    "device_time_ms": 0.0,
                    "cpu_memory_usage_MB": 103.1268310546875,
                    "self_cpu_memory_usage_MB": -46.868133544921875,
                    "device_memory_usage_MB": 0.0,
                    "self_device_memory_usage_MB": 0.0,
                    "energy_consumption_execution": 0,
                    "disk_IO_MB": 0,
                    "input_data_MB": 0,
                    "output_data_MB": 0,
                    "execution_time_ms": 390.5464808146159,
                    "execution_cost": 0
                },
                {
                    "xai_method": "RandomCAM",
                    "cpu_time_ms": 228.500874,
                    "device_time_ms": 0.0,
                    "cpu_memory_usage_MB": 103.3302001953125,
                    "self_cpu_memory_usage_MB": -125.6288833618164,
                    "device_memory_usage_MB": 0.0,
                    "self_device_memory_usage_MB": 0.0,
                    "energy_consumption_execution": 0,
                    "disk_IO_MB": 0,
                    "input_data_MB": 0,
                    "output_data_MB": 0,
                    "execution_time_ms": 784.5149834950765,
                    "execution_cost": 0
                }
            ],
            "idle_container_cpu_memory_usage": "1.5GB",
            "idle_container_device_memory_usage": "0GB"
        }
    ],
    "feedback": {
        "likes": [],
        "dislikes": [],
        "comments": []
    },
    "code": {
        "readme_content": "---\nlicense: apache-2.0\ntags:\n- vision\n- image-classification\n\ndatasets:\n- imagenet-1k\n\nwidget:\n- src: https://huggingface.co/datasets/mishig/sample_images/resolve/main/tiger.jpg\n  example_title: Tiger\n- src: https://huggingface.co/datasets/mishig/sample_images/resolve/main/teapot.jpg\n  example_title: Teapot\n- src: https://huggingface.co/datasets/mishig/sample_images/resolve/main/palace.jpg\n  example_title: Palace\n\n---\n\n# RegNet\n\nRegNet model trained on imagenet-1k. It was introduced in the paper [Designing Network Design Spaces](https://arxiv.org/abs/2003.13678) and first released in [this repository](https://github.com/facebookresearch/pycls). \n\nDisclaimer: The team releasing RegNet did not write a model card for this model so this model card has been written by the Hugging Face team.\n\n## Model description\n\nThe authors design search spaces to perform Neural Architecture Search (NAS). They first start from a high dimensional search space and iteratively reduce the search space by empirically applying constraints based on the best-performing models sampled by the current search space.\n\n![model image](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/regnet_architecture.png)\n\n## Intended uses & limitations\n\nYou can use the raw model for image classification. See the [model hub](https://huggingface.co/models?search=regnet) to look for\nfine-tuned versions on a task that interests you.\n\n### How to use\n\nHere is how to use this model:\n\n```python\n>>> from transformers import AutoFeatureExtractor, RegNetForImageClassification\n>>> import torch\n>>> from datasets import load_dataset\n\n>>> dataset = load_dataset(\"huggingface/cats-image\")\n>>> image = dataset[\"test\"][\"image\"][0]\n\n>>> feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/regnet-y-040\")\n>>> model = RegNetForImageClassification.from_pretrained(\"facebook/regnet-y-040\")\n\n>>> inputs = feature_extractor(image, return_tensors=\"pt\")\n\n>>> with torch.no_grad():\n...     logits = model(**inputs).logits\n\n>>> # model predicts one of the 1000 ImageNet classes\n>>> predicted_label = logits.argmax(-1).item()\n>>> print(model.config.id2label[predicted_label])\n'tabby, tabby cat'\n```\n\nFor more code examples, we refer to the [documentation](https://huggingface.co/docs/transformers/master/en/model_doc/regnet).",
        "dockerfile_content": "# Base image for AI service powered by HuggingFace pre-trained AI models.\n# the image has the following packages/libraries installed already:\n# - python3.12, pip, git, fastapi, uvicorn, torch, torchvision, opencv-python, transformers, python-multipart, Pillow, requests\nFROM python3.12_ai_service_base:latest\n\n# Set working directory\nWORKDIR /app\n\n# Copy application code\nCOPY . .\n\n# Install additional dependencies\nRUN pip install datasets\n\n# Expose port 8000\nEXPOSE 8000\n\n# Start the FastAPI server\nCMD [\"uvicorn\", \"ai_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\", \"--timeout-keep-alive\", \"600\"]",
        "ai_server_script_content": "import json\nimport os\nimport time\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import JSONResponse\nfrom contextlib import asynccontextmanager\nfrom ai_server_utils import (\n    PROFILE_OUTPUT_JSON_SPEC,\n    NODE_ID,\n    K8S_POD_NAME,\n)\n\n\n# -------------------------------------------\n# App Lifespan setup\n# -------------------------------------------\n# Record the script start time (when uvicorn starts the process)\nSCRIPT_START_TIME = time.time()\nINITIALIZATION_DURATION = 0.0\nservice_endpoint_specs = {\n    \"model_input_form_spec\": None,\n    \"model_output_json_spec\": None,\n    \"profile_output_json_spec\": None,\n    \"xai_model_input_form_spec\": None,\n    \"xai_model_output_json_spec\": None,\n    \"xai_profile_output_json_spec\": None,\n}\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n\n    global INITIALIZATION_DURATION\n    global SCRIPT_START_TIME\n    global service_endpoint_specs\n\n    # Load the AI model\n    print(\"Loading AI model...\")\n    from model import (\n        MODEL_INPUT_FORM_SPEC,\n        MODEL_OUTPUT_JSON_SPEC,\n        router as model_router,\n    )\n\n    service_endpoint_specs[\"model_input_form_spec\"] = MODEL_INPUT_FORM_SPEC\n    service_endpoint_specs[\"model_output_json_spec\"] = MODEL_OUTPUT_JSON_SPEC\n    service_endpoint_specs[\"profile_output_json_spec\"] = PROFILE_OUTPUT_JSON_SPEC\n\n    app.include_router(model_router, prefix=\"/model\", tags=[\"AI Model\"])\n\n    # Load the XAI model\n    if os.path.exists(os.path.dirname(__file__) + \"/xai_model.py\"):\n        print(\"Loading XAI model...\")\n        from xai_model import (\n            XAI_OUTPUT_JSON_SPEC,\n            router as xai_model_router,\n        )\n\n        # by default, the xai_model input form spec is the same as the model input form spec\n        service_endpoint_specs[\"xai_model_input_form_spec\"] = MODEL_INPUT_FORM_SPEC\n        service_endpoint_specs[\"xai_model_output_json_spec\"] = MODEL_OUTPUT_JSON_SPEC\n        service_endpoint_specs[\"xai_model_output_json_spec\"].update(\n            XAI_OUTPUT_JSON_SPEC\n        )\n        service_endpoint_specs[\"xai_profile_output_json_spec\"] = (\n            PROFILE_OUTPUT_JSON_SPEC\n        )\n        service_endpoint_specs[\"xai_profile_output_json_spec\"].update(\n            XAI_OUTPUT_JSON_SPEC\n        )\n\n        app.include_router(xai_model_router, prefix=\"/xai_model\", tags=[\"XAI Model\"])\n\n    # Record the initialization duration\n    INITIALIZATION_DURATION = time.time() - SCRIPT_START_TIME\n\n    print(f\"AI service loaded in {INITIALIZATION_DURATION:.2f} seconds.\")\n\n    yield\n\n    # Clean up the models and release the resources\n    service_endpoint_specs.clear()\n\n\n# -------------------------------------------\n# FastAPI application setup\n# -------------------------------------------\napp = FastAPI(lifespan=lifespan)\n\n\n# -------------------------------------------\n# Middlewares\n# -------------------------------------------\n@app.middleware(\"http\")\nasync def prepare_header_middleware(request: Request, call_next):\n    start_time = time.perf_counter()\n    response = await call_next(request)\n    process_time = time.perf_counter() - start_time\n    response.headers[\"X-Process-Time\"] = str(process_time)\n    response.headers[\"X-NODE-ID\"] = NODE_ID\n    response.headers[\"X-K8S-POD-NAME\"] = K8S_POD_NAME\n    return response\n\n\n# -------------------------------------------\n# General Endpoints\n# -------------------------------------------\n@app.get(\"/initialization_duration\")\ndef get_initialization_duration():\n    \"\"\"\n    Endpoint to retrieve the initialization duration of the AI model.\n    \"\"\"\n    global INITIALIZATION_DURATION\n\n    if INITIALIZATION_DURATION == 0.0:\n        return JSONResponse(\n            content={\"error\": \"Model not initialized.\"},\n            status_code=500,\n        )\n    return JSONResponse(\n        content={\n            \"initialization_duration\": INITIALIZATION_DURATION,\n            \"script_start_time\": SCRIPT_START_TIME,\n        }\n    )\n\n\n@app.get(\"/help\")\ndef get_help():\n    global service_endpoint_specs\n    help_info = {\n        \"endpoints\": {\n            \"/model/run\": {\n                \"method\": \"POST\",\n                \"description\": \"Executes the AI model with the provided input data.\",\n                \"parameters\": {\n                    \"ue_id\": \"User Equipment ID (string) for tracking the request.\",\n                    **service_endpoint_specs[\"model_input_form_spec\"],\n                },\n                \"response\": {\n                    \"ue_id\": \"User Equipment ID (string) for tracking the request.\",\n                    **service_endpoint_specs[\"model_output_json_spec\"],\n                },\n            },\n            \"/model/profile_run\": {\n                \"method\": \"POST\",\n                \"description\": \"Profiles the AI model execution.\",\n                \"parameters\": {\n                    \"ue_id\": \"User Equipment ID (string) for tracking the request.\",\n                    **service_endpoint_specs[\"model_input_form_spec\"],\n                },\n                \"response\": {\n                    \"ue_id\": \"User Equipment ID (string) for tracking the request.\",\n                    \"profile_result\": \"Profiling results of the AI model execution.\",\n                    **service_endpoint_specs[\"profile_output_json_spec\"],\n                },\n            },\n            \"/initialization_duration\": {\n                \"method\": \"GET\",\n                \"description\": \"Retrieves the initialization duration of the AI model.\",\n                \"response\": {\n                    \"initialization_duration\": \"Time taken to initialize the model (in seconds).\",\n                    \"script_start_time\": \"Timestamp when the script started (in seconds since epoch).\",\n                },\n            },\n        }\n    }\n\n    if service_endpoint_specs[\"xai_model_input_form_spec\"] is not None:\n        help_info[\"endpoints\"][\"/xai_model/run\"] = {\n            \"method\": \"POST\",\n            \"description\": \"Executes the XAI model with the provided input data.\",\n            \"parameters\": {\n                \"ue_id\": \"User Equipment ID (string) for tracking the request.\",\n                **service_endpoint_specs[\"xai_model_input_form_spec\"],\n            },\n            \"response\": {\n                \"ue_id\": \"User Equipment ID (string) for tracking the request.\",\n                **service_endpoint_specs[\"xai_model_output_json_spec\"],\n            },\n        }\n\n        help_info[\"endpoints\"][\"/xai_model/profile_run\"] = {\n            \"method\": \"POST\",\n            \"description\": \"Profiles the XAI model execution.\",\n            \"parameters\": {\n                \"ue_id\": \"User Equipment ID (string) for tracking the request.\",\n                **service_endpoint_specs[\"xai_model_input_form_spec\"],\n            },\n            \"response\": {\n                \"ue_id\": \"User Equipment ID (string) for tracking the request.\",\n                \"profile_result\": \"Profiling results of the XAI model execution.\",\n                **service_endpoint_specs[\"xai_profile_output_json_spec\"],\n            },\n        }\n    \n    return JSONResponse(content=help_info)\n",
        "ai_server_utils_script_content": "import os\nimport socket\nimport torch\nfrom io import BytesIO\nimport base64\n\nfrom torch.profiler import profile, ProfilerActivity, record_function\n\n\n# -------------------------------------------\n# ENV Variables\n# -------------------------------------------\nNODE_ID = os.getenv(\"NODE_ID\", socket.gethostname())\nK8S_POD_NAME = os.getenv(\"K8S_POD_NAME\", \"UNKNOWN\")\n\n\n# -------------------------------------------\n# Profile Utils\n# -------------------------------------------\nprofile_activities = [\n    ProfilerActivity.CPU,\n    ProfilerActivity.CUDA,\n    ProfilerActivity.MTIA,\n    ProfilerActivity.XPU,\n]\n\ndef process_model_output_logits(model, model_output_logits):\n    \"\"\"\n    Process the model outputs to prepare for the response.\n    \"\"\"\n    probabilities = torch.nn.functional.softmax(model_output_logits[0], dim=0)\n\n    # Return the top 5 predictions with labels\n    top5_prob, top5_catid = torch.topk(probabilities, 5)\n    predictions = []\n    for i in range(top5_prob.size(0)):\n        category_id = top5_catid[i].item()\n        predictions.append(\n            {\n                \"category_id\": category_id,\n                \"label\": model.config.id2label[category_id],\n                \"probability\": top5_prob[i].item(),\n            }\n        )\n    return predictions\n\ndef prepare_profile_results(prof):\n    \"\"\"\n    Prepare the profile results for the model inputs and outputs.\n    \"\"\"\n    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n\n    profile_event = prof.key_averages()[0]\n\n    profile_result = {\n        \"name\": profile_event.key,\n        \"device_type\": str(profile_event.device_type),\n        \"device_name\": str(profile_event.use_device),\n        \"cpu_memory_usage\": profile_event.cpu_memory_usage,\n        \"self_cpu_memory_usage\": profile_event.self_cpu_memory_usage,\n        \"device_memory_usage\": profile_event.device_memory_usage,\n        \"self_device_memory_usage\": profile_event.self_device_memory_usage,\n        \"cpu_time_total\": profile_event.cpu_time_total,\n        \"self_cpu_time_total\": profile_event.self_cpu_time_total,\n        \"device_time_total\": profile_event.device_time_total,\n        \"self_device_time_total\": profile_event.self_device_time_total,\n    }\n    return profile_result\n\n\ndef encode_image(image):\n    \"\"\"\n    Encode the image to bytes\n    \"\"\"\n    buffered = BytesIO()\n    image.save(buffered, format=\"PNG\")\n    encoded_image = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n    return encoded_image\n\n\nPROFILE_OUTPUT_JSON_SPEC = {\n    \"ue_id\": \"unique execution ID\",\n    \"profile_result\": {\n        \"name\": \"name of the profile event\",\n        \"device_type\": \"type of device used (e.g., CPU, GPU, ...)\",\n        \"device_name\": \"name of the device used\",\n        \"cpu_memory_usage\": \"CPU memory usage in bytes\",\n        \"self_cpu_memory_usage\": \"self CPU memory usage in bytes\",\n        \"device_memory_usage\": \"device memory usage in bytes\",\n        \"self_device_memory_usage\": \"self device memory usage in bytes\",\n        \"cpu_time_total\": \"total CPU time in microseconds\",\n        \"self_cpu_time_total\": \"self total CPU time in microseconds\",\n        \"device_time_total\": \"total device time in microseconds\",\n        \"self_device_time_total\": \"self total device time in microseconds\",\n    },\n    \"model_results\": \"the AI service model results\",\n}\n",
        "ai_client_script_content": "import base64\nimport json\nimport time\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nimport matplotlib.pyplot as plt\nfrom ai_client_utils import (\n    prepare_ai_service_request_files,\n    prepare_ai_service_request_data,\n)\n\nXAI_GRADCAM_METHODS = [\n    \"GradCAM\",\n    \"HiResCAM\",\n    # \"AblationCAM\",\n    \"XGradCAM\",\n    \"GradCAMPlusPlus\",\n    # \"ScoreCAM\",\n    \"LayerCAM\",\n    \"EigenCAM\",\n    \"EigenGradCAM\",\n    \"KPCA_CAM\",\n    \"RandomCAM\",\n]\n\n# -------------------------------------\n# prompt for necessary inputs\n# -------------------------------------\nSERVER_URL = input(\"Please input server URL (default to http://localhost:9000): \")\nif SERVER_URL.strip() == \"\":\n    SERVER_URL = \"http://localhost:9000\"\nUE_ID = input(\"Please input UE_ID (default to 123456): \")\nif UE_ID.strip() == \"\":\n    UE_ID = \"123456\"\n\n\ndef send_post_request(url, data, files):\n    \"\"\"Send request to run AI service and display AI service responses.\"\"\"\n    try:\n        response = requests.post(url, files=files, data=data)\n        # get the process time, node id and k8s pod name from the response headers\n        process_time = response.headers.get(\"X-Process-Time\")\n        node_id = response.headers.get(\"X-NODE-ID\")\n        k8s_pod_name = response.headers.get(\"X-K8S-POD-NAME\")\n        if response.status_code == 200:\n            return response.json(), process_time, node_id, k8s_pod_name\n        else:\n            print(f\"Error: {response.status_code}, {response.text}\")\n            return None\n    except Exception as e:\n        print(f\"Request failed: {e}\")\n        return None\n\n\ndef send_get_request(url, params=None):\n    \"\"\"Send GET request to the specified URL and return the response.\"\"\"\n    try:\n        response = requests.get(url, params=params)\n        process_time = response.headers.get(\"X-Process-Time\")\n        node_id = response.headers.get(\"X-NODE-ID\")\n        k8s_pod_name = response.headers.get(\"X-K8S-POD-NAME\")\n        if response.status_code == 200:\n            return response.json(), process_time, node_id, k8s_pod_name\n        else:\n            print(f\"Error: {response.status_code}, {response.text}\")\n            return None\n    except requests.exceptions.RequestException as e:\n        print(f\"Request failed: {e}\")\n        return None\n\n\nclass ProfileResultProcessor:\n\n    def __init__(self, server_url):\n        self.server_url = server_url\n        self.start_time = time.time()\n        self.service_initialization_duration = 0\n        self.response_counter = 0\n        self.profile_name = None\n        self.device_type = None\n        self.device_name = None\n        self.node_id = None\n        self.k8s_pod_name = None\n        self.cpu_memory_usage_bytes = 0\n        self.self_cpu_memory_usage_bytes = 0\n        self.device_memory_usage_bytes = 0\n        self.self_device_memory_usage_bytes = 0\n        self.cpu_time_total_us = 0\n        self.self_cpu_time_total_us = 0\n        self.device_time_total_us = 0\n        self.self_device_time_total_us = 0\n\n        # xai related\n        self.gradcam_method_name = None\n\n        self.fetch_service_initialization_duration()\n\n    def fetch_service_initialization_duration(self):\n        \"\"\"Fetch the service initialization duration from the server.\"\"\"\n        response, process_time, node_id, k8s_pod_name = send_get_request(\n            f\"{self.server_url}/initialization_duration\"\n        )\n        if response:\n            self.service_initialization_duration = response.get(\n                \"initialization_duration\", 0\n            )\n        else:\n            print(\"Failed to fetch initialization duration.\")\n            self.service_initialization_duration = 0\n\n    def process_new_response(\n        self,\n        profile_response,\n        process_time=None,\n        node_id=None,\n        k8s_pod_name=None,\n        gradcam_method_name=None,\n    ):\n        if not profile_response:\n            return\n\n        profile_result = profile_response[\"profile_result\"]\n\n        if not profile_result:\n            return\n\n        if self.profile_name is None:\n            self.profile_name = profile_result[\"name\"]\n        if self.device_type is None:\n            self.device_type = profile_result[\"device_type\"]\n        if self.device_name is None:\n            self.device_name = profile_result[\"device_name\"]\n        if self.node_id is None:\n            self.node_id = node_id\n        if self.k8s_pod_name is None:\n            self.k8s_pod_name = k8s_pod_name\n\n        if self.gradcam_method_name is None:\n            self.gradcam_method_name = gradcam_method_name\n\n        # update the max profile result\n        self.cpu_memory_usage_bytes = max(\n            self.cpu_memory_usage_bytes, profile_result[\"cpu_memory_usage\"]\n        )\n        # self cpu memory usage could be negative. here we take the value that has the max absolute value\n        if abs(profile_result[\"self_cpu_memory_usage\"]) > abs( self.self_cpu_memory_usage_bytes):\n            self.self_cpu_memory_usage_bytes = profile_result[\"self_cpu_memory_usage\"]\n        self.device_memory_usage_bytes = max(\n            self.device_memory_usage_bytes, profile_result[\"device_memory_usage\"]\n        )\n        # same as self cpu memory usage\n        if abs(profile_result[\"self_device_memory_usage\"]) > abs(self.self_device_memory_usage_bytes):\n            self.self_device_memory_usage_bytes = profile_result[\"self_device_memory_usage\"]\n        self.cpu_time_total_us = max(\n            self.cpu_time_total_us, profile_result[\"cpu_time_total\"]\n        )\n        self.self_cpu_time_total_us = max(\n            self.self_cpu_time_total_us, profile_result[\"self_cpu_time_total\"]\n        )\n        self.device_time_total_us = max(\n            self.device_time_total_us, profile_result[\"device_time_total\"]\n        )\n        self.self_device_time_total_us = max(\n            self.self_device_time_total_us, profile_result[\"self_device_time_total\"]\n        )\n\n        self.response_counter += 1\n\n    def complete_profile(self):\n        print(\"\\n--------- PROFILE EVENT ---------\\n\")\n        print(f\"Name: {self.profile_name}\")\n        print(f\"Device Type: {self.device_type}\")\n        print(f\"Device Name: {self.device_name}\")\n        print(f\"Node ID: {self.node_id}\")\n        print(f\"K8S_POD_NAME: {self.k8s_pod_name}\")\n\n        if self.gradcam_method_name:\n            print(f\"GradCAM Method Name: {self.gradcam_method_name}\")\n\n        print(\"\\n--------- LATENCY RESULT ---------\\n\")\n        print(\"Service Initialization Duration: \", self.service_initialization_duration)\n        print(\"Total Requests: \", self.response_counter)\n        print(f\"Total Time Taken: {time.time() - self.start_time:.2f} seconds\")\n        print(\n            f\"Average Time Taken: {(time.time() - self.start_time) / self.response_counter:.2f} seconds\"\n        )\n\n        print(\"\\n--------- RESOURCE USAGE ---------\\n\")\n        print(f\"CPU Memory Usage: {self.cpu_memory_usage_bytes / (1024 * 1024):.2f} MB\")\n        print(\n            f\"Self CPU Memory Usage: {self.self_cpu_memory_usage_bytes / (1024 * 1024):.2f} MB\"\n        )\n        print(\n            f\"Device Memory Usage: {self.device_memory_usage_bytes / (1024 * 1024):.2f} MB\"\n        )\n        print(\n            f\"Self Device Memory Usage: {self.self_device_memory_usage_bytes / (1024 * 1024):.2f} MB\"\n        )\n        print(f\"CPU Time Total: {self.cpu_time_total_us / 1000:.2f} ms\")\n        print(f\"Self CPU Time Total: {self.self_cpu_time_total_us / 1000:.2f} ms\")\n        print(f\"Device Time Total: {self.device_time_total_us / 1000:.2f} ms\")\n        print(f\"Self Device Time Total: {self.self_device_time_total_us / 1000:.2f} ms\")\n\n        # update the service_data.json automatically\n        with open(\"service_data.json\", \"r\") as f:\n            service_data = json.load(f)\n\n        if not self.gradcam_method_name:\n            complete_profile_data_to_save = {\n                \"node_id\": self.node_id,\n                \"device_type\": self.device_type,\n                \"device_name\": self.device_name,\n                \"initialization_time_ms\": self.service_initialization_duration * 1000,\n                \"eviction_time_ms\": 0,\n                \"initialization_cost\": 0,\n                \"keep_alive_cost\": 0,\n                \"energy_consumption_idle\": 0,\n                \"inference\": {\n                    \"cpu_time_ms\": self.cpu_time_total_us / 1000,\n                    \"device_time_ms\": self.device_time_total_us / 1000,\n                    \"cpu_memory_usage_MB\": self.cpu_memory_usage_bytes\n                    / (1024 * 1024),\n                    \"self_cpu_memory_usage_MB\": self.self_cpu_memory_usage_bytes\n                    / (1024 * 1024),\n                    \"device_memory_usage_MB\": self.device_memory_usage_bytes\n                    / (1024 * 1024),\n                    \"self_device_memory_usage_MB\": self.self_device_memory_usage_bytes\n                    / (1024 * 1024),\n                    \"energy_consumption_execution\": 0,\n                    \"disk_IO_MB\": 0,\n                    \"input_data_MB\": 0,\n                    \"output_data_MB\": 0,\n                    \"execution_time_ms\": (time.time() - self.start_time)\n                    / self.response_counter\n                    * 1000,\n                    \"execution_cost\": 0,\n                },\n            }\n\n            # check if there is already a profile for this node id\n            profile_found = False\n            for profile in service_data[\"profiles\"]:\n                if profile[\"node_id\"] == self.node_id:\n                    profile[\"inference\"] = complete_profile_data_to_save[\"inference\"]\n                    profile_found = True\n                    break\n            if not profile_found:\n                service_data[\"profiles\"].append(complete_profile_data_to_save)\n\n            # save the updated service_data.json\n            with open(\"service_data.json\", \"w\") as f:\n                json.dump(service_data, f, indent=4)\n            print(\"\\n--------- SERVICE DATA UPDATED ---------\\n\")\n\n        else:\n            complete_xai_profile_data_to_save = {\n                \"node_id\": self.node_id,\n                \"device_type\": self.device_type,\n                \"device_name\": self.device_name,\n                \"initialization_time_ms\": self.service_initialization_duration * 1000,\n                \"eviction_time_ms\": 0,\n                \"initialization_cost\": 0,\n                \"keep_alive_cost\": 0,\n                \"energy_consumption_idle\": 0,\n                \"xai\": [\n                    {\n                        \"xai_method\": self.gradcam_method_name,\n                        \"cpu_time_ms\": self.cpu_time_total_us / 1000,\n                        \"device_time_ms\": self.device_time_total_us / 1000,\n                        \"cpu_memory_usage_MB\": self.cpu_memory_usage_bytes\n                        / (1024 * 1024),\n                        \"self_cpu_memory_usage_MB\": self.self_cpu_memory_usage_bytes\n                        / (1024 * 1024),\n                        \"device_memory_usage_MB\": self.device_memory_usage_bytes\n                        / (1024 * 1024),\n                        \"self_device_memory_usage_MB\": self.self_device_memory_usage_bytes\n                        / (1024 * 1024),\n                        \"energy_consumption_execution\": 0,\n                        \"disk_IO_MB\": 0,\n                        \"input_data_MB\": 0,\n                        \"output_data_MB\": 0,\n                        \"execution_time_ms\": (time.time() - self.start_time)\n                        / self.response_counter\n                        * 1000,\n                        \"execution_cost\": 0,\n                    }\n                ],\n            }\n\n            # check if there is already a profile for this node id\n            profile_found = False\n            for profile in service_data[\"profiles\"]:\n                if profile[\"node_id\"] == self.node_id:\n                    profile_found = True\n\n                    # check if there is already a profile for this xai method\n                    xai_method_found = False\n                    if not profile.get(\"xai\"):\n                        profile[\"xai\"] = []\n                    for xai_profile in profile[\"xai\"]:\n                        if xai_profile[\"xai_method\"] == self.gradcam_method_name:\n                            xai_profile.update(complete_xai_profile_data_to_save[\"xai\"][0]) \n                            xai_method_found = True\n                            break\n                    if not xai_method_found:\n                        profile[\"xai\"].append(complete_xai_profile_data_to_save[\"xai\"][0])\n                    break\n\n            if not profile_found:\n                service_data[\"profiles\"].append(complete_xai_profile_data_to_save)\n\n            # save the updated service_data.json\n            with open(\"service_data.json\", \"w\") as f:\n                json.dump(service_data, f, indent=4)\n            print(\"\\n--------- SERVICE DATA UPDATED ---------\\n\")\n\n\ndef option_run():\n    data = prepare_ai_service_request_data()\n    files = prepare_ai_service_request_files()\n    data = {**data, \"ue_id\": UE_ID}\n    response, process_time, node_id, pod_name = send_post_request(\n        f\"{SERVER_URL}/model/run\", data, files\n    )\n    print(\"Process Time: \", process_time)\n    print(\"Node ID: \", node_id)\n    print(\"K8S_POD_NAME: \", pod_name)\n    print(\"Response\")\n    print(json.dumps(response, indent=4))\n\n\ndef option_profile_run():\n    data = prepare_ai_service_request_data()\n    data = {**data, \"ue_id\": UE_ID}\n    files = prepare_ai_service_request_files()\n    num_requests = int(input(\"Enter the number of requests to send: \"))\n\n    try:\n        profile_result_processor = ProfileResultProcessor(SERVER_URL)\n\n        for _ in range(num_requests):\n            profile_response, process_time, node_id, k8s_node_name = send_post_request(\n                f\"{SERVER_URL}/model/profile_run\", data, files\n            )\n            print(\"Process Time: \", process_time)\n            print(\"Node ID: \", node_id)\n            print(\"K8S_POD_NAME: \", k8s_node_name)\n            print(\"Response\")\n            print(json.dumps(profile_response, indent=4))\n            if not profile_response:\n                print(\"No profile response received.\")\n                continue\n\n            profile_result_processor.process_new_response(\n                profile_response,\n                process_time=process_time,\n                node_id=node_id,\n                k8s_pod_name=k8s_node_name,\n            )\n\n        # Print the final profile result and update the service_data.json\n        profile_result_processor.complete_profile()\n\n    except requests.exceptions.RequestException as e:\n        print(f\"Request failed: {e}\")\n\n\ndef option_help():\n    \"\"\"Get help information from the server.\"\"\"\n    try:\n        response, process_time, node_id, pod_name = send_get_request(\n            f\"{SERVER_URL}/help\"\n        )\n        print(\"Process Time: \", process_time)\n        print(\"Node ID: \", node_id)\n        print(\"K8S_POD_NAME: \", pod_name)\n        print(\"Response\")\n        print(json.dumps(response, indent=4))\n    except Exception as e:\n        print(f\"Request failed: {e}\")\n\n\ndef option_run_with_xai():\n    \"\"\"Run AI service with XAI.\"\"\"\n    data = prepare_ai_service_request_data()\n    files = prepare_ai_service_request_files()\n\n    print(\n        \"Note that currently only GradCAM methods on image-classification models are supported.\"\n    )\n    while True:\n        gradcam_method_name = input(\n            f\"Please select a GradCAM method (options: {XAI_GRADCAM_METHODS}): \"\n        )\n        if gradcam_method_name not in XAI_GRADCAM_METHODS:\n            print(f\"Invalid GradCAM method. Please select again.\")\n        else:\n            break\n\n    # ask for target class for explanation\n    target_category_indexes = input(\n        \"Please input target category indexes for explanation (comma-separated, e.g., 111, 32, 44, ...): \"\n    )\n    if not target_category_indexes or not target_category_indexes.strip():\n        print(\n            \"No target category indexes provided. Defaulting to explaining the top confident category.\"\n        )\n        target_category_indexes = []\n    else:\n        target_category_indexes = [\n            int(i.strip()) for i in target_category_indexes.split(\",\")\n        ]\n\n    data = {\n        **data,\n        \"ue_id\": UE_ID,\n        \"gradcam_method_name\": gradcam_method_name,\n        \"target_category_indexes\": target_category_indexes,\n    }\n    print(\"Data: \", data)\n    response, process_time, node_id, k8s_pod_name = send_post_request(\n        f\"{SERVER_URL}/xai_model/run\", data, files\n    )\n    print(\"Process Time: \", process_time)\n    print(\"Node ID: \", node_id)\n    print(\"K8S_POD_NAME: \", k8s_pod_name)\n\n    # Handle JSON response\n    model_results = response.get(\"model_results\")\n    if model_results:\n        print(\"Model Results:\", json.dumps(model_results, indent=4))\n\n    xai_results = response.get(\"xai_results\")\n    if xai_results:\n        print(\"XAI Results Method:\", xai_results.get(\"xai_method\"))\n\n    # Handle binary image response\n    encoded_image = xai_results.get(\"image\")\n    if encoded_image:\n        image_bytes = base64.b64decode(encoded_image)\n\n        # Load the image into Pillow\n        image = Image.open(BytesIO(image_bytes))\n\n        # Save image to disk\n        image.save(\"xai_output.png\")\n\n        # Display the image using matplotlib\n        plt.imshow(image)\n        plt.axis(\"off\")\n        plt.show()\n\n\ndef option_profile_run_with_xai():\n    \"\"\"Run AI service with XAI and profile the run.\"\"\"\n    data = prepare_ai_service_request_data()\n    files = prepare_ai_service_request_files()\n    print(\n        \"Note that currently only GradCAM methods on image-classification models are supported.\"\n    )\n\n    # ask for target class for explanation\n    target_category_indexes = input(\n        \"Please input target category indexes for explanation (comma-separated, e.g., 111, 32, 44, ...): \"\n    )\n    if not target_category_indexes or not target_category_indexes.strip():\n        print(\n            \"No target category indexes provided. Defaulting to explaining the top confident category.\"\n        )\n        target_category_indexes = []\n    else:\n        target_category_indexes = [\n            int(i.strip()) for i in target_category_indexes.split(\",\")\n        ]\n\n    num_requests = int(input(\"Enter the number of requests to send: \"))\n\n    try:\n        for gradcam_method_name in XAI_GRADCAM_METHODS:\n\n            data = {\n                **data,\n                \"ue_id\": UE_ID,\n                \"gradcam_method_name\": gradcam_method_name,\n                \"target_category_indexes\": target_category_indexes,\n            }\n            print(\"Data: \", data)\n\n            profile_result_processor = ProfileResultProcessor(SERVER_URL)\n\n            for _ in range(num_requests):\n                response, process_time, node_id, k8s_pod_name = send_post_request(\n                    f\"{SERVER_URL}/xai_model/profile_run\", data, files\n                )\n                print(\"Process Time: \", process_time)\n                print(\"Node ID: \", node_id)\n                print(\"K8S_POD_NAME: \", k8s_pod_name)\n                if not response:\n                    print(\"No profile response received.\")\n                    continue\n\n                # Handle JSON response\n                model_results = response.get(\"model_results\")\n                if model_results:\n                    print(\"Model Results:\", json.dumps(model_results, indent=4))\n\n                profile_result_processor.process_new_response(\n                    response,\n                    process_time=process_time,\n                    node_id=node_id,\n                    k8s_pod_name=k8s_pod_name,\n                    gradcam_method_name=gradcam_method_name,\n                )\n\n            # Print the final profile result and update the service_data.json\n            profile_result_processor.complete_profile()\n\n    except requests.exceptions.RequestException as e:\n        print(f\"Request failed: {e}\")\n\n\nOPTIONS = [\n    {\n        \"label\": \"Get help information\",\n        \"action\": option_help,\n    },\n    {\n        \"label\": \"Run AI service\",\n        \"action\": option_run,\n    },\n    {\n        \"label\": \"Profile AI service\",\n        \"action\": option_profile_run,\n    },\n    {\n        \"label\": \"Run AI service with XAI (only image-classification models)\",\n        \"action\": option_run_with_xai,\n    },\n    {\n        \"label\": \"Profile AI service with XAI (only image-classification models)\",\n        \"action\": option_profile_run_with_xai,\n    },\n]\n\n\nif __name__ == \"__main__\":\n    while True:\n        print(\"\\nOptions:\")\n        for i, option in enumerate(OPTIONS, start=1):\n            print(f\"{i}. {option['label']}\")\n        print(\"q. Quit\")\n        choice = input(\"Enter your choice: \")\n\n        if choice == \"q\":\n            print(\"Exiting the client. Goodbye!\")\n            break\n        else:\n            try:\n                choice = int(choice)\n                if 1 <= choice <= len(OPTIONS):\n                    OPTIONS[choice - 1][\"action\"]()\n                else:\n                    print(\"Invalid choice. Please try again.\")\n            except ValueError:\n                print(\"Invalid input. Please enter a number.\")\n",
        "ai_client_utils_script_content": "def prepare_ai_service_request_files():\n    \"\"\"Prepare the `files` part for the AI service request.\"\"\"\n    files = {}\n    image_file_path = input(\"Please input the image file path: \")\n    with open(image_file_path, \"rb\") as image_file:\n        files[\"file\"] = image_file.read()\n    return files\n\n\ndef prepare_ai_service_request_data():\n    \"\"\"Prepare the `data` part other than `ue_id` for the AI service request.\"\"\"\n    data = {}\n    ue_id = input(\"Please input the unique execution ID (ue_id): \")\n    data[\"ue_id\"] = ue_id\n    return data",
        "model_script_content": "# import server utils\nfrom ai_server_utils import (\n    process_model_output_logits,\n    profile_activities,\n    prepare_profile_results,\n)\n# import profile utils\nfrom torch.profiler import profile, record_function\n\n# import necessary libs for AI model inference and request handling\nimport torch\nfrom fastapi import APIRouter, File, Form, UploadFile\nfrom fastapi.responses import JSONResponse\nfrom transformers import AutoFeatureExtractor, RegNetForImageClassification\nfrom PIL import Image\n\n# --------------------------------\n# Model-specific configuration\n# make sure the variables `MODEL_NAME` and `model` are defined here.\n# --------------------------------\nMODEL_NAME = \"facebook/regnet-y-040\"\nfeature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)\nmodel = RegNetForImageClassification.from_pretrained(MODEL_NAME)\nmodel.eval()\n\n# Initialize the FastAPI router\nrouter = APIRouter()\n\n@router.post(\"/run\")\nasync def run_model(file: UploadFile = File(...), ue_id: str = Form(...)):\n    try:\n        # Prepare the model input\n        image = Image.open(file.file).convert(\"RGB\")\n        inputs = feature_extractor(images=image, return_tensors=\"pt\")\n\n        # Perform inference\n        with torch.no_grad():\n            outputs = model(**inputs)\n\n        # Process the model outputs\n        predictions = process_model_output_logits(model, outputs.logits)\n\n        return JSONResponse(\n            content={\n                \"ue_id\": ue_id,\n                \"model_results\": predictions,\n            }\n        )\n    except Exception as e:\n        print(f\"Error processing file: {e}\")\n        return JSONResponse(\n            content={\"error\": \"Failed to process the image. {e}\".format(e=str(e))},\n            status_code=500,\n        )\n\n@router.post(\"/profile_run\")\nasync def profile_run(file: UploadFile = File(...), ue_id: str = Form(...)):\n    \"\"\"\n    Endpoint to profile the AI model execution.\n    \"\"\"\n    try:\n        # Prepare the model input\n        image = Image.open(file.file).convert(\"RGB\")\n        inputs = feature_extractor(images=image, return_tensors=\"pt\")\n\n        # perform profiling\n        with profile(\n            activities=profile_activities,\n            profile_memory=True,\n        ) as prof:\n            with record_function(\"model_run\"):\n                with torch.no_grad():\n                    model_outputs = model(**inputs)\n\n        profile_result = prepare_profile_results(prof)\n\n        # Process the model outputs\n        predictions = process_model_output_logits(model, model_outputs.logits)\n\n        return JSONResponse(\n            content={\n                \"ue_id\": ue_id,\n                \"profile_result\": profile_result,\n                \"model_results\": predictions,\n            }\n        )\n\n    except Exception as e:\n        print(f\"Error processing request: {e}\")\n        return JSONResponse(\n            content={\"error\": f\"Failed to process the request. {e}\"},\n            status_code=500,\n        )\n\n# Below are the model input and output specifications to be used by the `/help` endpoint\nMODEL_INPUT_FORM_SPEC = {\n    \"file\": {\n        \"type\": \"file upload\",\n        \"description\": \"The image file to be classified.\",\n        \"required\": True,\n        \"example\": \"puppy.png\",\n    }\n}\n\nMODEL_OUTPUT_JSON_SPEC = {\n    \"ue_id\": \"unique execution ID\",\n    \"model_results\": [\n        {\n            \"category_id\": \"category id\",\n            \"label\": \"category label\",\n            \"probability\": \"probability value\",\n        }\n    ],\n}",
        "healthcheck_script_content": "import requests\n\nprint(requests.get(\"http://localhost:8000/help\"))",
        "xai_model_script_content": "from typing import Callable, List, Optional\nfrom fastapi import APIRouter, File, Form, UploadFile\nfrom fastapi.responses import JSONResponse\nfrom PIL import Image\nfrom torch.profiler import profile, record_function\nfrom pytorch_grad_cam import (\n    GradCAM,\n    HiResCAM,\n    AblationCAM,\n    XGradCAM,\n    GradCAMPlusPlus,\n    ScoreCAM,\n    LayerCAM,\n    EigenCAM,\n    EigenGradCAM,\n    KPCA_CAM,\n    RandomCAM,\n)\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom PIL import Image\nimport numpy as np\nimport torch\nfrom torchvision import transforms\nfrom transformers import AutoImageProcessor\nfrom typing import List, Optional\n\n\n# import model utilities\nfrom ai_server_utils import (\n    encode_image,\n    prepare_profile_results,\n    process_model_output_logits,\n    profile_activities,\n)\n\n# Currently only support GradCAM on image-classification models.\n# so we import the model directly from the model.py file\nfrom model import model, MODEL_NAME\n\n\nresize_and_normalize_processor = AutoImageProcessor.from_pretrained(\n    MODEL_NAME, use_fast=True\n)\nresize_only_processor = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n    ],\n)\n\nGRADCAM_METHODS = {\n    \"GradCAM\": GradCAM,\n    \"HiResCAM\": HiResCAM,\n    \"AblationCAM\": AblationCAM,\n    \"XGradCAM\": XGradCAM,\n    \"GradCAMPlusPlus\": GradCAMPlusPlus,\n    \"ScoreCAM\": ScoreCAM,\n    \"LayerCAM\": LayerCAM,\n    \"EigenCAM\": EigenCAM,\n    \"EigenGradCAM\": EigenGradCAM,\n    \"KPCA_CAM\": KPCA_CAM,\n    \"RandomCAM\": RandomCAM,\n}\n\n\nclass HuggingfaceToTensorModelWrapper(torch.nn.Module):\n    \"\"\"Model wrapper to return a tensor\"\"\"\n\n    def __init__(self, model):\n        super(HuggingfaceToTensorModelWrapper, self).__init__()\n        self.model = model\n\n    def forward(self, x):\n        return self.model(x).logits\n\n\ndef get_model_to_tensor_wrapper_class():\n    \"\"\"Helper function to get the model wrapper class.\"\"\"\n    return HuggingfaceToTensorModelWrapper\n\n\ndef get_target_layers_for_grad_cam(model: torch.nn.Module):\n    \"\"\"Helper function to get the target layer for GradCAM.\"\"\"\n    return [model.resnet.encoder.stages[-1].layers[-1]]\n\n\ndef get_classifier_output_target_class():\n    \"\"\"Helper function to get the classifier output target class.\"\"\"\n    return ClassifierOutputTarget\n\n\ndef get_reshape_transform():\n    \"\"\"Helper function to get the reshape transform for GradCAM.\"\"\"\n    return None\n\n\ndef run_grad_cam_on_image(\n    model: torch.nn.Module,\n    target_layers: List[torch.nn.Module],\n    targets_for_gradcam: Optional[List[Callable]],\n    reshape_transform: Optional[Callable],\n    input_tensor: torch.nn.Module,\n    input_image: Image,\n    gradcam_method: Callable,\n):\n    \"\"\"Helper function to run GradCAM on an image and create a visualization.\n    Since the classification target is None, the highest scoring category will be used for every image in the batch.\n    \"\"\"\n\n    with gradcam_method(\n        model=model,\n        target_layers=target_layers,\n        reshape_transform=reshape_transform,\n    ) as cam:\n\n        # Replicate the tensor for each of the categories we want to create Grad-CAM for:\n        repeated_tensor = input_tensor[None, :].repeat(\n            (\n                1\n                if targets_for_gradcam is None or len(targets_for_gradcam) == 0\n                else len(targets_for_gradcam)\n            ),\n            1,\n            1,\n            1,\n        )\n\n        batch_results = cam(\n            input_tensor=repeated_tensor,\n            targets=(\n                None\n                if targets_for_gradcam is None or len(targets_for_gradcam) == 0\n                else targets_for_gradcam\n            ),\n        )\n        results = []\n        for grayscale_cam in batch_results:\n            # adjust the shape of the input_image from (3, 244, 244) to (244, 244, 3)\n            visualization = show_cam_on_image(\n                np.float32(input_image.permute(1, 2, 0).numpy()),\n                grayscale_cam,\n                use_rgb=True,\n            )\n            results.append(visualization)\n        output_image = Image.fromarray(np.hstack(results))\n\n        return output_image, cam.outputs\n\n\n# Initialize the FastAPI router\nrouter = APIRouter()\n\n\n@router.post(\"/run\")\nasync def run_model(\n    file: UploadFile = File(...),\n    ue_id: str = Form(...),\n    gradcam_method_name: str = Form(...),\n    target_category_indexes: Optional[List[int]] = Form(None),\n):\n    \"\"\"\n    Endpoint to run the XAI model.\"\"\"\n\n    try:\n        # Prepare the model input\n        print(\"Preparing the model input...\")\n        image = Image.open(file.file).convert(\"RGB\")\n        normalized_image_tensor = resize_and_normalize_processor(\n            images=image, return_tensors=\"pt\"\n        )[\"pixel_values\"].squeeze(0)\n        original_image_tensor = resize_only_processor(image)\n\n        if target_category_indexes is None or len(target_category_indexes) == 0:\n            targets_for_gradcam = None\n        else:\n            # Convert to output target from category indexes\n            targets_for_gradcam = [\n                ClassifierOutputTarget(index) for index in target_category_indexes\n            ]\n        assert (\n            gradcam_method_name in GRADCAM_METHODS\n        ), f\"GradCAM method '{gradcam_method_name}' is not supported. \"\n        gradcam_method = GRADCAM_METHODS[gradcam_method_name]\n\n        model_wrapper_class = get_model_to_tensor_wrapper_class()\n        target_layers = get_target_layers_for_grad_cam(model)\n        reshape_transform = get_reshape_transform()\n\n        # Perform inference\n        print(\"Running GradCAM...\")\n        xai_image, model_output_logits = run_grad_cam_on_image(\n            model=model_wrapper_class(model),\n            target_layers=target_layers,\n            targets_for_gradcam=targets_for_gradcam,\n            reshape_transform=reshape_transform,\n            input_tensor=normalized_image_tensor,\n            input_image=original_image_tensor,\n            gradcam_method=gradcam_method,\n        )\n\n        predictions = process_model_output_logits(model, model_output_logits)\n\n        return JSONResponse(\n            {\n                \"ue_id\": ue_id,\n                \"xai_results\": {\n                    \"image\": encode_image(xai_image),\n                    \"xai_method\": gradcam_method_name,\n                },\n                \"model_results\": predictions,\n            }\n        )\n\n    except Exception as e:\n        print(f\"Error processing file: {e}\")\n        return JSONResponse(\n            content={\"error\": \"Failed to process the image. {e}\".format(e=str(e))},\n            status_code=500,\n        )\n\n\n@router.post(\"/profile_run\")\nasync def profile_run(\n    file: UploadFile = File(...),\n    ue_id: str = Form(...),\n    gradcam_method_name: str = Form(...),\n    target_category_indexes: Optional[List[int]] = Form(None),\n):\n    \"\"\"\n    Endpoint to profile the XAI run.\n    \"\"\"\n    try:\n        # Prepare the model input\n        image = Image.open(file.file).convert(\"RGB\")\n        normalized_image_tensor = resize_and_normalize_processor(\n            images=image, return_tensors=\"pt\"\n        )[\"pixel_values\"].squeeze(0)\n        original_image_tensor = resize_only_processor(image)\n        if target_category_indexes is None or len(target_category_indexes) == 0:\n            targets_for_gradcam = None\n        else:\n            # Convert to output target from category indexes\n            targets_for_gradcam = [\n                ClassifierOutputTarget(index) for index in target_category_indexes\n            ]\n\n        assert (\n            gradcam_method_name in GRADCAM_METHODS\n        ), f\"GradCAM method '{gradcam_method_name}' is not supported. \"\n        gradcam_method = GRADCAM_METHODS[gradcam_method_name]\n\n        model_wrapper_class = get_model_to_tensor_wrapper_class()\n        target_layers = get_target_layers_for_grad_cam(model)\n        reshape_transform = get_reshape_transform()\n\n        # perform profiling\n        with profile(\n            activities=profile_activities,\n            profile_memory=True,\n        ) as prof:\n            with record_function(\"xai_model_run\"):\n\n                # Perform inference\n                xai_image, model_output_logits = run_grad_cam_on_image(\n                    model=model_wrapper_class(model),\n                    target_layers=target_layers,\n                    targets_for_gradcam=targets_for_gradcam,\n                    reshape_transform=reshape_transform,\n                    input_tensor=normalized_image_tensor,\n                    input_image=original_image_tensor,\n                    gradcam_method=gradcam_method,\n                )\n\n        return JSONResponse(\n            {\n                \"ue_id\": ue_id,\n                \"xai_results\": {\n                    \"image\": encode_image(xai_image),\n                    \"xai_method\": gradcam_method_name,\n                },\n                \"model_results\": process_model_output_logits(\n                    model, model_output_logits\n                ),\n                \"profile_result\": prepare_profile_results(prof),\n            }\n        )\n\n    except Exception as e:\n        print(f\"Error processing request: {e}\")\n        return JSONResponse(\n            content={\"error\": f\"Failed to process the request. {e}\"},\n            status_code=500,\n        )\n\n\nXAI_OUTPUT_JSON_SPEC = {\n    \"xai_results\": {\n        \"image\": \"XAI image result\",\n        \"xai_method\": \"XAI method used\",\n    }\n}\n"
    }
}